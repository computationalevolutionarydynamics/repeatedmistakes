{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated Games With Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nikolas Skoufis, 23/10/15\n",
    "## Supervisor: Julian Garcia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prisoner's Dilemma\n",
    "\n",
    "* Game between two prisoners who can either cooperate or defect\n",
    "* Can encode outcomes in a payoff matrix\n",
    "* Nash equilibrium is for both players to defect\n",
    "* Iterated prisoner's dilemma is multiple rounds of the prisoner's dilemma\n",
    "* Best strategy is to always defect, unless the number of rounds are variable\n",
    "* If rounds are variable TFT is the best strategy (cf. Axelrod's tournaments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected payoff\n",
    "\n",
    "* Can compute the expected value of the payoff between two strategies\n",
    "\n",
    "$$\\sum_{i=0}^{\\infty} = \\delta^i \\pi_i$$\n",
    "\n",
    "* Closed forms for simple pairs of strategies\n",
    "* Quickly becomes difficult for non-deterministic strategies\n",
    "* Mistakes complicate all of this!\n",
    "* Which strategies are fault tolerant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and software\n",
    "\n",
    "* Github for version control\n",
    "* Travis for CI, Coveralls for code coverage\n",
    "\n",
    "<img src=\"CoverallsAndTravis.png\">\n",
    "\n",
    "* Nose for testing, Hypothesis for property based testing\n",
    "* Consider some simple code that encodes and decodes text to/from some character encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "from hypothesis import given\n",
    "from hypothesis.strategies import text\n",
    "\n",
    "@given(text())\n",
    "def test_decode_inverts_encode(s):\n",
    "    assert decode(encode(s)) == s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "* Need a way to simulate and analyse different strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT: ['D', 'C', 'D', 'C', 'D', 'C', 'D', 'C', 'D', 'C']\n",
      "TFT: ['C', 'D', 'C', 'D', 'C', 'D', 'C', 'D', 'C', 'D']\n"
     ]
    }
   ],
   "source": [
    "from repeatedmistakes.strategies import SuspiciousTitForTat, TitForTat\n",
    "from repeatedmistakes.repeatedgame import RepeatedGame\n",
    "\n",
    "my_game = RepeatedGame(SuspiciousTitForTat, TitForTat)\n",
    "simulation_results = my_game.simulate(10)\n",
    "print(\"STFT: \" + str(simulation_results[SuspiciousTitForTat]))\n",
    "print(\"TFT: \" + str(simulation_results[TitForTat]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* All strategies inherit from a base `Strategy` class\n",
    "* Arbitrary strategies can be simulated, including non-deterministic ones because history is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation strategies\n",
    "\n",
    "### Monte Carlo\n",
    "\n",
    "* Monte Carlo methods, single processor and multiprocessor (using `multiprocessing` module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payoff for fixed number of trials: (3.2026104417670673, 2.8917670682730918)\n",
      "Payoff with estimator stdev: (3.1718510405257385, 2.8581599123767791)\n"
     ]
    }
   ],
   "source": [
    "from repeatedmistakes.simulations_multiprocessed import simulate_payoff\n",
    "from repeatedmistakes.repeatedgame import PrisonersDilemmaPayoff\n",
    "\n",
    "# Fixed number of trials\n",
    "fixed_payoff = simulate_payoff(SuspiciousTitForTat, TitForTat, PrisonersDilemmaPayoff(),\n",
    "                               continuation_probability=0.9, mistake_probability=0.01, trials=1000)\n",
    "\n",
    "# With estimator stdev\n",
    "estimator_payoff = simulate_payoff(SuspiciousTitForTat, TitForTat, PrisonersDilemmaPayoff(),\n",
    "                                   continuation_probability=0.9, mistake_probability=0.01, estimator_stdev=0.2)\n",
    "\n",
    "print(\"Payoff for fixed number of trials: \" + str(fixed_payoff))\n",
    "print(\"Payoff with estimator stdev: \" + str(estimator_payoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smart brute force\n",
    "\n",
    "* Computational method using a queue and bounding of terms\n",
    "* Amenable to multiprocessing, but large overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Set up a variable for the expected payoff\n",
    "expected_payoff = 0\n",
    "\n",
    "# Set up a queue to hold the partial histories\n",
    "q = Queue()\n",
    "\n",
    "# Initialize the queue with an empty history, with probability 1\n",
    "q.put((1, '', ''))\n",
    "\n",
    "while not q.empty():\n",
    "\n",
    "    # Get an item from the front of the queue\n",
    "    item = q.get()\n",
    "\n",
    "    # Set up Strategy objects with the given histories\n",
    "    player_one = Strategy(item.history1)\n",
    "    player_two = Strategy(item.history2)\n",
    "\n",
    "    # Compute the moves that the strategies produce with the given histories, passing the opponent's history as well\n",
    "    move_one = player_one.next_move(player_two.history)\n",
    "    move_two = player_two.next_move(player_one.history)\n",
    "\n",
    "    # Compute the probability of no mistakes occurring\n",
    "    probability = item.probability * no_mistake_probability * continuation_probability\n",
    "\n",
    "    # If this maximum possible term size is larger than the threshold\n",
    "    if probability * max_payoff > epsilon:\n",
    "        # Multiply this by the payoff from the outcome of a no-mistake round to find the term\n",
    "        term = probability * payoff(move_one, move_two)\n",
    "        # Add the term to the expected payoff\n",
    "        expected_payoff += term\n",
    "        # Add the probability along with the histories (including the new moves) back onto the queue\n",
    "        q.put(probability,\n",
    "              item.history1 + move_one,\n",
    "              item.history2 + move_two)\n",
    "\n",
    "    else:\n",
    "        # The probability was too small, so don't add it back to the queue\n",
    "\n",
    "    # Repeat this for each of the two one mistake cases and the two mistake case\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart brute force results: (3.143265506166684, 2.830829466232284)\n"
     ]
    }
   ],
   "source": [
    "from repeatedmistakes.calculations_multiprocessed import calculate_payoff_with_mistakes\n",
    "\n",
    "results = calculate_payoff_with_mistakes(SuspiciousTitForTat, TitForTat, PrisonersDilemmaPayoff(),\n",
    "                                        continuation_probability=0.9, mistake_probability=0.01,\n",
    "                                        epsilon=1e-6)\n",
    "\n",
    "print(\"Smart brute force results: \" + str(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected value only\n",
    "\n",
    "* Similar to the last method, but only consider games with length = expected length\n",
    "* Fast but not really that accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value only results: (1.1522687480742237, 1.1330642689396533)\n"
     ]
    }
   ],
   "source": [
    "from repeatedmistakes.expected_only import expected_only\n",
    "\n",
    "results = expected_only(SuspiciousTitForTat, TitForTat, PrisonersDilemmaPayoff(),\n",
    "                        continuation_probability=0.9, mistake_probability=0.01,\n",
    "                        epsilon=1e-6)\n",
    "\n",
    "print(\"Expected value only results: \" + str(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "* Simluations were run on the Monash Campus Cluster\n",
    "* Simulations take a long time to get accurate results, even with multiprocessing\n",
    "\n",
    "### MCC\n",
    "\n",
    "* Heterogeneous cluster (low cores + high ram, high cores + low ram, gpus)\n",
    "* Submit jobs using job files to Sun Grid Engine with `qsub`\n",
    "* Wrote a script to generate batch files based on array and then submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "#$ -S /bin/sh\n",
    "#$ -m bea\n",
    "#$ -M nmsko2@student.monash.edu\n",
    "#$ -l h_vmem=8G\n",
    "#$ -pe smp 8\n",
    "module load python/3.4.3\n",
    "python3 simulation.py 0.9 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Great for doing large computations\n",
    "* Shared resource, finding free machine with multiple cores is hard!\n",
    "\n",
    "### Calculations\n",
    "\n",
    "* Calculations were run on home machine\n",
    "* Take on the order or seconds...\n",
    "* ...unless you've got a large mistake probability.\n",
    "\n",
    "### Comparing the methods\n",
    "\n",
    "* All three methods run on different continuation probabilities and mistake probabilities\n",
    "* Run for different combinations of strategies\n",
    "* Simulations run with ~100,000 trials per strategy pair per parameter pair\n",
    "* Calculations run with varying minimum term size down to 1e-6\n",
    "\n",
    "* Relative error between simulations and calculations for TF2T vs Inverse TFT, 1e-6 epsilon\n",
    "\n",
    "<img src=\"TFNT.png\">\n",
    "\n",
    "* Not only is large mistake probability slow, it's also inaccurate (lots of leaves)\n",
    "* Expected value method only useful for low continuation probability, not usually considered\n",
    "\n",
    "### Application\n",
    "\n",
    "* Expected payoffs are used for drawing phase diagrams\n",
    "* Phase diagrams drawn using Mathematic notebook Dynamo\n",
    "* Replicator dynamics over three populations, AllC, AllD, TFT\n",
    "* Continuation probability = 0.9\n",
    "* Mistake probability = 1e-4\n",
    "* Min term size = 1e-6\n",
    "\n",
    "#### Simulations\n",
    "\n",
    "<img src=\"sims_simplex.png\">\n",
    "\n",
    "#### Calculations\n",
    "\n",
    "<img src=\"calcs_simplex.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* Writing efficient multi-process code is hard!\n",
    "* Good tools make your life easier\n",
    "* It's possible to quickly calculate expected payoff with minimal accuracy loss, so long as your mistake probability is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Ask me!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
